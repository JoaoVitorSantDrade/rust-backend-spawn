# Rinha de Backend 2025 - Implementa√ß√£o em Rust

Esta √© uma implementa√ß√£o para a terceira edi√ß√£o da Rinha de Backend, desenvolvida em Rust com foco em alta performance, resili√™ncia e baixo consumo de recursos.

## Tecnologias Utilizadas

* **Linguagem:** Rust (stable)
* **Framework Web:** Axum
* **Runtime Ass√≠ncrono:** Tokio
* **Banco de Dados:** Redis (para persist√™ncia e sum√°rios pr√©-agregados)
* **Mensageria:**
    * **NATS:** Usado para a comunica√ß√£o de status de sa√∫de entre as inst√¢ncias da API (L√≠der e Colaboradora).
    * **Tokio MPSC:** Usado como a fila de trabalho interna para desacoplar o recebimento de requisi√ß√µes do processamento.
* **Load Balancer:** Nginx (padr√£o) / HAProxy (alternativa)
* **Serializa√ß√£o:** `simd-json` para desserializa√ß√£o de alta performance.
* **Alocador de Mem√≥ria:** `jemalloc` para gerenciamento de mem√≥ria mais eficiente em ambiente multi-threaded.
* **Containeriza√ß√£o:** Docker & Docker Compose

## Arquitetura Geral

A solu√ß√£o foi projetada para ser horizontalmente escal√°vel e resiliente, seguindo as especifica√ß√µes do desafio.

1.  **Load Balancer:** Um **Nginx** (ou **HAProxy**) atua como a porta de entrada, recebendo todo o tr√°fego na porta `9999` e distribuindo a carga entre duas inst√¢ncias da API.
2.  **API (Rust/Axum):** Duas inst√¢ncias da aplica√ß√£o rodam em cont√™ineres separados.
    * A inst√¢ncia **L√çDER** √© respons√°vel por realizar os *health checks* peri√≥dicos nos processadores de pagamento externos e transmitir o status via NATS.
    * A inst√¢ncia **COLABORADORA** (e tamb√©m a L√çDER) escuta as mensagens de status no NATS para manter seu estado interno sobre a sa√∫de dos processadores sempre atualizado.
3.  **Fila de Trabalho:** O endpoint `POST /payments` √© extremamente r√°pido. Ele apenas valida a requisi√ß√£o e a envia para uma fila de trabalho interna (MPSC), respondendo `200 OK` imediatamente.
4.  **Workers:** Um pool de workers (tarefas Tokio) consome os pagamentos da fila em background. √â aqui que toda a l√≥gica de neg√≥cio acontece: escolher o melhor processador, fazer a chamada HTTP, tratar falhas e retentativas.
5.  **Persist√™ncia (Redis):** Ap√≥s um pagamento ser processado com sucesso, o worker o salva no Redis. A persist√™ncia √© otimizada usando duas estrat√©gias:
    * **Dados Individuais:** Cada pagamento √© salvo com um √≠ndice de tempo de alta precis√£o (microssegundos) para permitir consultas exatas.
    * **Sum√°rios Pr√©-agregados:** Na mesma transa√ß√£o, contadores para o sum√°rio daquele **segundo** espec√≠fico s√£o incrementados, tornando a consulta `GET /payments-summary` quase instant√¢nea.

## Explica√ß√£o das Branches

Este reposit√≥rio cont√©m diferentes estrat√©gias de implementa√ß√£o, cada uma em sua branch, para explorar os trade-offs de concorr√™ncia e infraestrutura.

### üå≥ `round_robin` (Branch Principal)
Esta √© a implementa√ß√£o principal e a mais perform√°tica, utilizada na imagem Docker final.

* **Estrat√©gia:** Elimina completamente a conten√ß√£o de locks na fila de trabalho.
* **Como Funciona:** Em vez de uma √∫nica fila compartilhada, cada worker possui seu pr√≥prio canal MPSC dedicado. O handler `submit_work_handler` atua como um dispatcher: ele usa um contador at√¥mico para distribuir as requisi√ß√µes de pagamento recebidas entre os canais dos workers em um padr√£o **Round-Robin**.
* **Vantagem:** Permite que todos os workers fiquem 100% paralelos, sem nunca precisarem esperar um pelo outro para pegar um novo trabalho da fila. √â a arquitetura de maior vaz√£o (throughput).

### üå≥ `haproxy`
Esta branch √© funcionalmente id√™ntica √† `round_robin`, com uma √∫nica mudan√ßa na infraestrutura.

* **Estrat√©gia:** Substituir o Nginx pelo HAProxy como load balancer.
* **Como Funciona:** O arquivo `docker-compose.yaml` foi modificado para usar o servi√ßo do `haproxy` em vez do `nginx`. Um arquivo `haproxy.cfg` foi adicionado com otimiza√ß√µes de performance e health checks ativos.
* **Vantagem:** O HAProxy oferece health checks mais robustos e proativos, podendo parar de enviar tr√°fego para uma inst√¢ncia da API que travou, o que aumenta a resili√™ncia geral do sistema. OBS: N√£o utilizo o health check

### üå≥ `pool`
Esta branch implementa uma estrat√©gia de concorr√™ncia mais simples, mas com um ponto de conten√ß√£o.

* **Estrat√©gia:** Todos os workers compartilham um √∫nico receptor da fila.
* **Como Funciona:** Existe apenas um canal MPSC. O lado do receptor (`Receiver`) √© envolvido em um `Arc<Mutex<...>>`. Todos os workers, em um loop, competem para obter o `lock` do Mutex e ter a chance de chamar `.recv().await` para pegar o pr√≥ximo pagamento da fila.
* **Vantagem:** C√≥digo de inicializa√ß√£o um pouco mais simples.
* **Desvantagem:** O `Mutex` se torna um gargalo. Apenas um worker pode estar esperando por um item da fila por vez, o que limita a escalabilidade e a vaz√£o em compara√ß√£o com a abordagem `round_robin`.